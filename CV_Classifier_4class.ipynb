{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d5e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 4\n",
      "Class names: ['Broccoli', 'Mango', 'Nut', 'Pepper']\n",
      "Data directory: C:\\Users\\ashsh\\Downloads\n",
      "\n",
      "=== Broccoli ===\n",
      "  Subfolders found: ['Florets', 'In-Context(Cooking)', 'Whole Crown']\n",
      "    Florets: 1000 images\n",
      "    In-Context(Cooking): 1000 images\n",
      "    Whole Crown: 1000 images\n",
      "  Total for Broccoli: 3000 images\n",
      "\n",
      "=== Mango ===\n",
      "  Subfolders found: ['Cubed,Hedgehog', 'Sliced,Peeled', 'Whole']\n",
      "    Cubed,Hedgehog: 1006 images\n",
      "    Sliced,Peeled: 1509 images\n",
      "    Whole: 1019 images\n",
      "  Total for Mango: 3534 images\n",
      "\n",
      "=== Nut ===\n",
      "  Subfolders found: ['Chopped,Crushed', 'In-Shell', 'Shelled']\n",
      "    Chopped,Crushed: 1000 images\n",
      "    In-Shell: 1000 images\n",
      "    Shelled: 1000 images\n",
      "  Total for Nut: 3000 images\n",
      "\n",
      "=== Pepper ===\n",
      "  Subfolders found: ['Diced,Sliced', 'Halved,Deseeded', 'Whole']\n",
      "    Diced,Sliced: 1006 images\n",
      "    Halved,Deseeded: 1038 images\n",
      "    Whole: 1018 images\n",
      "  Total for Pepper: 3062 images\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total images across all classes: 12596\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class_names = ['Broccoli', 'Mango', 'Nut', 'Pepper']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "data_dir = r\"C:\\Users\\ashsh\\Downloads\"  \n",
    "print(f\"Data directory: {data_dir}\")\n",
    "\n",
    "\n",
    "def explore_folder_structure(base_path, class_names):\n",
    "    total_images = 0\n",
    "    for class_name in class_names:\n",
    "        folder_path = os.path.join(base_path, class_name)\n",
    "        if os.path.exists(folder_path):\n",
    "            print(f\"\\n=== {class_name} ===\")\n",
    "            class_total = 0\n",
    "            \n",
    "            \n",
    "            direct_images = [f for f in os.listdir(folder_path) \n",
    "                           if f.lower().endswith(('.png', '.jpg', '.jpeg')) and \n",
    "                           os.path.isfile(os.path.join(folder_path, f))]\n",
    "            if direct_images:\n",
    "                print(f\"  Direct images: {len(direct_images)}\")\n",
    "                class_total += len(direct_images)\n",
    "            \n",
    "       \n",
    "            subfolders = [d for d in os.listdir(folder_path) \n",
    "                         if os.path.isdir(os.path.join(folder_path, d))]\n",
    "            \n",
    "            if subfolders:\n",
    "                print(f\"  Subfolders found: {subfolders}\")\n",
    "                for subfolder in subfolders:\n",
    "                    subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                    images_in_subfolder = [f for f in os.listdir(subfolder_path) \n",
    "                                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                    print(f\"    {subfolder}: {len(images_in_subfolder)} images\")\n",
    "                    class_total += len(images_in_subfolder)\n",
    "            \n",
    "            print(f\"  Total for {class_name}: {class_total} images\")\n",
    "            total_images += class_total\n",
    "        else:\n",
    "            print(f\"Warning: {class_name} folder not found at {folder_path}\")\n",
    "    \n",
    "    print(f\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Total images across all classes: {total_images}\")\n",
    "\n",
    "explore_folder_structure(data_dir, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4aa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Train dataset created with 10076 images\n",
      "  Broccoli: 2400 images\n",
      "  Mango: 2827 images\n",
      "  Nut: 2400 images\n",
      "  Pepper: 2449 images\n",
      "Test dataset created with 2520 images\n",
      "  Broccoli: 600 images\n",
      "  Mango: 707 images\n",
      "  Nut: 600 images\n",
      "  Pepper: 613 images\n",
      "\n",
      "DataLoaders created:\n",
      "Train batches: 315\n",
      "Test batches: 79\n",
      "\n",
      "Sample batch shape: torch.Size([32, 3, 224, 224])\n",
      "Sample labels shape: torch.Size([32])\n",
      "Data loading successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "class_names = ['Broccoli', 'Mango', 'Nut', 'Pepper']\n",
    "num_classes = len(class_names)\n",
    "data_dir = r\"C:\\Users\\ashsh\\Downloads\"\n",
    "\n",
    "\n",
    "class ProduceDataset(Dataset):\n",
    "    def __init__(self, data_dir, class_names, transform=None, train=True, train_split=0.8):\n",
    "        self.data_dir = data_dir\n",
    "        self.class_names = class_names\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "        \n",
    "        # Collect all image paths and labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in class_names:\n",
    "            class_folder = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_folder):\n",
    "   \n",
    "                subfolders = [d for d in os.listdir(class_folder) \n",
    "                             if os.path.isdir(os.path.join(class_folder, d))]\n",
    "                \n",
    "                class_images = []\n",
    "                for subfolder in subfolders:\n",
    "                    subfolder_path = os.path.join(class_folder, subfolder)\n",
    "                    images_in_subfolder = [f for f in os.listdir(subfolder_path) \n",
    "                                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                    \n",
    "                    for img_name in images_in_subfolder:\n",
    "                        img_path = os.path.join(subfolder_path, img_name)\n",
    "                        class_images.append(img_path)\n",
    "                \n",
    "            \n",
    "                train_imgs, test_imgs = train_test_split(class_images, \n",
    "                                                       train_size=train_split, \n",
    "                                                       random_state=42)\n",
    "                \n",
    "                if train:\n",
    "                    selected_images = train_imgs\n",
    "                else:\n",
    "                    selected_images = test_imgs\n",
    "                \n",
    "    \n",
    "                self.image_paths.extend(selected_images)\n",
    "                self.labels.extend([self.class_to_idx[class_name]] * len(selected_images))\n",
    "        \n",
    "        print(f\"{'Train' if train else 'Test'} dataset created with {len(self.image_paths)} images\")\n",
    "        \n",
    "\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            count = self.labels.count(i)\n",
    "            print(f\"  {class_name}: {count} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = ProduceDataset(data_dir, class_names, transform=train_transforms, train=True)\n",
    "test_dataset = ProduceDataset(data_dir, class_names, transform=test_transforms, train=False)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"\\nSample batch shape: {sample_batch[0].shape}\")\n",
    "    print(f\"Sample labels shape: {sample_batch[1].shape}\")\n",
    "    print(\"Data loading successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading batch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e6ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ResNet model with frozen backbone...\n",
      "Backbone frozen - only training final classification layer\n",
      "Total parameters: 11,178,564\n",
      "Trainable parameters: 2,052\n",
      "Frozen parameters: 11,176,512\n",
      "Percentage trainable: 0.02%\n",
      "\n",
      "Model created successfully!\n",
      "Loss function: CrossEntropyLoss\n",
      "Optimizer: Adam (lr=0.001, weight_decay=1e-4)\n",
      "Scheduler: StepLR (step_size=7, gamma=0.1)\n",
      "\n",
      "Testing forward pass...\n",
      "Input shape: torch.Size([2, 3, 224, 224])\n",
      "Output shape: torch.Size([2, 4])\n",
      "Output example: tensor([-0.2891, -0.7783,  0.2104,  0.3842], device='cuda:0')\n",
      "Forward pass successful!\n",
      "\n",
      "Real batch test:\n",
      "Input batch shape: torch.Size([32, 3, 224, 224])\n",
      "True labels: tensor([3, 2, 2, 0, 1], device='cuda:0')\n",
      "Predicted labels: tensor([2, 2, 2, 2, 2], device='cuda:0')\n",
      "Real batch test successful!\n"
     ]
    }
   ],
   "source": [
    "# Create ResNet model with transfer learning\n",
    "class ProduceClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4, pretrained=True, freeze_backbone=True):\n",
    "        super(ProduceClassifier, self).__init__()\n",
    "        \n",
    "    \n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "      \n",
    "        num_features = self.resnet.fc.in_features\n",
    "        \n",
    "\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            \n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "\n",
    "            for param in self.resnet.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            print(\"Backbone frozen - only training final classification layer\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = ProduceClassifier(num_classes=num_classes, pretrained=True, freeze_backbone=True)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen_params = total_params - trainable_params\n",
    "    return total_params, trainable_params, frozen_params\n",
    "\n",
    "total_params, trainable_params, frozen_params = count_parameters(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "print(f\"\\nTesting forward pass...\")\n",
    "try:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_input = torch.randn(2, 3, 224, 224).to(device)\n",
    "        output = model(sample_input)\n",
    "        print(f\"Input shape: {sample_input.shape}\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        print(f\"Output example: {output[0]}\")\n",
    "        print(\"Forward pass successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in forward pass: {e}\")\n",
    "\n",
    "\n",
    "def test_real_batch():\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            images, labels = next(iter(train_loader))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            print(f\"\\nReal batch test:\")\n",
    "            print(f\"Input batch shape: {images.shape}\")\n",
    "            print(f\"True labels: {labels[:5]}\")\n",
    "            print(f\"Predicted labels: {predicted[:5]}\")\n",
    "            print(\"Real batch test successful!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in real batch test: {e}\")\n",
    "\n",
    "test_real_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Number of epochs: 15\n",
      "Batch size: 32\n",
      "Learning rate: 0.001\n",
      "Device: cuda\n",
      "Model save directory: saved_models\n",
      "\n",
      "Starting training for 15 epochs...\n",
      "Training on 10076 samples\n",
      "Testing on 2520 samples\n",
      "--------------------------------------------------\n",
      "Epoch 1/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.9111\n",
      "  Batch 100/315, Loss: 0.7951\n",
      "  Batch 150/315, Loss: 0.4582\n",
      "  Batch 200/315, Loss: 0.5305\n",
      "  Batch 250/315, Loss: 0.5171\n",
      "  Batch 300/315, Loss: 0.5292\n",
      "Testing...\n",
      "Results - Train Loss: 0.6299, Train Acc: 0.7722\n",
      "         Test Loss: 0.3086, Test Acc: 0.9036\n",
      "         LR: 0.001000, Time: 2042.18s\n",
      "--------------------------------------------------\n",
      "Epoch 2/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.2443\n",
      "  Batch 100/315, Loss: 0.3699\n",
      "  Batch 150/315, Loss: 0.3877\n",
      "  Batch 200/315, Loss: 0.2505\n",
      "  Batch 250/315, Loss: 0.3311\n",
      "  Batch 300/315, Loss: 0.3233\n",
      "Testing...\n",
      "Results - Train Loss: 0.4041, Train Acc: 0.8580\n",
      "         Test Loss: 0.3360, Test Acc: 0.8714\n",
      "         LR: 0.001000, Time: 1983.95s\n",
      "--------------------------------------------------\n",
      "Epoch 3/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.4789\n",
      "  Batch 100/315, Loss: 0.1914\n",
      "  Batch 150/315, Loss: 0.3488\n",
      "  Batch 200/315, Loss: 0.3489\n",
      "  Batch 250/315, Loss: 0.3493\n",
      "  Batch 300/315, Loss: 0.5041\n",
      "Testing...\n",
      "Results - Train Loss: 0.3561, Train Acc: 0.8721\n",
      "         Test Loss: 0.2279, Test Acc: 0.9183\n",
      "         LR: 0.001000, Time: 1934.09s\n",
      "--------------------------------------------------\n",
      "Epoch 4/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.3816\n",
      "  Batch 100/315, Loss: 0.1965\n",
      "  Batch 150/315, Loss: 0.2540\n",
      "  Batch 200/315, Loss: 0.2589\n",
      "  Batch 250/315, Loss: 0.5912\n",
      "  Batch 300/315, Loss: 0.2507\n",
      "Testing...\n",
      "Results - Train Loss: 0.3299, Train Acc: 0.8818\n",
      "         Test Loss: 0.2092, Test Acc: 0.9242\n",
      "         LR: 0.001000, Time: 2730.51s\n",
      "--------------------------------------------------\n",
      "Epoch 5/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.1578\n",
      "  Batch 100/315, Loss: 0.1962\n",
      "  Batch 150/315, Loss: 0.3286\n",
      "  Batch 200/315, Loss: 0.3513\n",
      "  Batch 250/315, Loss: 0.0995\n",
      "  Batch 300/315, Loss: 0.2954\n",
      "Testing...\n",
      "Results - Train Loss: 0.3205, Train Acc: 0.8809\n",
      "         Test Loss: 0.2090, Test Acc: 0.9258\n",
      "         LR: 0.001000, Time: 1864.56s\n",
      "--------------------------------------------------\n",
      "Epoch 6/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.2780\n",
      "  Batch 100/315, Loss: 0.4414\n",
      "  Batch 150/315, Loss: 0.2193\n",
      "  Batch 200/315, Loss: 0.2269\n",
      "  Batch 250/315, Loss: 0.2599\n",
      "  Batch 300/315, Loss: 0.3938\n",
      "Testing...\n",
      "Results - Train Loss: 0.3103, Train Acc: 0.8870\n",
      "         Test Loss: 0.2063, Test Acc: 0.9270\n",
      "         LR: 0.001000, Time: 1885.34s\n",
      "--------------------------------------------------\n",
      "Epoch 7/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.1546\n",
      "  Batch 100/315, Loss: 0.3599\n",
      "  Batch 150/315, Loss: 0.1265\n",
      "  Batch 200/315, Loss: 0.3612\n",
      "  Batch 250/315, Loss: 0.1684\n",
      "  Batch 300/315, Loss: 0.4430\n",
      "Testing...\n",
      "Results - Train Loss: 0.2959, Train Acc: 0.8922\n",
      "         Test Loss: 0.2021, Test Acc: 0.9286\n",
      "         LR: 0.000100, Time: 1909.06s\n",
      "--------------------------------------------------\n",
      "Epoch 8/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.2286\n",
      "  Batch 100/315, Loss: 0.4159\n",
      "  Batch 150/315, Loss: 0.1712\n",
      "  Batch 200/315, Loss: 0.1166\n",
      "  Batch 250/315, Loss: 0.2551\n",
      "  Batch 300/315, Loss: 0.2554\n",
      "Testing...\n",
      "Results - Train Loss: 0.2827, Train Acc: 0.8983\n",
      "         Test Loss: 0.1999, Test Acc: 0.9306\n",
      "         LR: 0.000100, Time: 1843.02s\n",
      "--------------------------------------------------\n",
      "Epoch 9/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.6067\n",
      "  Batch 100/315, Loss: 0.2717\n",
      "  Batch 150/315, Loss: 0.1595\n",
      "  Batch 200/315, Loss: 0.4790\n",
      "  Batch 250/315, Loss: 0.4815\n",
      "  Batch 300/315, Loss: 0.2966\n",
      "Testing...\n",
      "Results - Train Loss: 0.2782, Train Acc: 0.9007\n",
      "         Test Loss: 0.2000, Test Acc: 0.9310\n",
      "         LR: 0.000100, Time: 1845.93s\n",
      "--------------------------------------------------\n",
      "Epoch 10/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.2014\n",
      "  Batch 100/315, Loss: 0.3302\n",
      "  Batch 150/315, Loss: 0.2656\n",
      "  Batch 200/315, Loss: 0.4232\n",
      "  Batch 250/315, Loss: 0.2950\n",
      "  Batch 300/315, Loss: 0.2834\n",
      "Testing...\n",
      "Results - Train Loss: 0.2749, Train Acc: 0.9007\n",
      "         Test Loss: 0.1986, Test Acc: 0.9302\n",
      "         LR: 0.000100, Time: 1834.08s\n",
      "--------------------------------------------------\n",
      "Epoch 11/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.0851\n",
      "  Batch 100/315, Loss: 0.1107\n",
      "  Batch 150/315, Loss: 0.3392\n",
      "  Batch 200/315, Loss: 0.2451\n",
      "  Batch 250/315, Loss: 0.1622\n",
      "  Batch 300/315, Loss: 0.1995\n",
      "Testing...\n",
      "Results - Train Loss: 0.2741, Train Acc: 0.8969\n",
      "         Test Loss: 0.1935, Test Acc: 0.9337\n",
      "         LR: 0.000100, Time: 1871.29s\n",
      "--------------------------------------------------\n",
      "Epoch 12/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.1655\n",
      "  Batch 100/315, Loss: 0.2692\n",
      "  Batch 150/315, Loss: 0.3009\n",
      "  Batch 200/315, Loss: 0.2763\n",
      "  Batch 250/315, Loss: 0.1319\n",
      "  Batch 300/315, Loss: 0.3371\n",
      "Testing...\n",
      "Results - Train Loss: 0.2776, Train Acc: 0.9012\n",
      "         Test Loss: 0.1863, Test Acc: 0.9337\n",
      "         LR: 0.000100, Time: 1852.25s\n",
      "--------------------------------------------------\n",
      "Epoch 13/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.2531\n",
      "  Batch 100/315, Loss: 0.5041\n",
      "  Batch 150/315, Loss: 0.3312\n",
      "  Batch 200/315, Loss: 0.3573\n",
      "  Batch 250/315, Loss: 0.2572\n",
      "  Batch 300/315, Loss: 0.1232\n",
      "Testing...\n",
      "Results - Train Loss: 0.2737, Train Acc: 0.9013\n",
      "         Test Loss: 0.1894, Test Acc: 0.9345\n",
      "         LR: 0.000100, Time: 1840.68s\n",
      "--------------------------------------------------\n",
      "Epoch 14/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.4834\n",
      "  Batch 100/315, Loss: 0.0971\n",
      "  Batch 150/315, Loss: 0.2194\n",
      "  Batch 200/315, Loss: 0.1543\n",
      "  Batch 250/315, Loss: 0.2080\n",
      "  Batch 300/315, Loss: 0.3296\n",
      "Testing...\n",
      "Results - Train Loss: 0.2739, Train Acc: 0.9031\n",
      "         Test Loss: 0.1958, Test Acc: 0.9294\n",
      "         LR: 0.000010, Time: 1814.17s\n",
      "--------------------------------------------------\n",
      "Epoch 15/15\n",
      "Training...\n",
      "  Batch 50/315, Loss: 0.3182\n",
      "  Batch 100/315, Loss: 0.3547\n",
      "  Batch 150/315, Loss: 0.4789\n",
      "  Batch 200/315, Loss: 0.2784\n",
      "  Batch 250/315, Loss: 0.1238\n",
      "  Batch 300/315, Loss: 0.2451\n",
      "Testing...\n",
      "Results - Train Loss: 0.2678, Train Acc: 0.9028\n",
      "         Test Loss: 0.1872, Test Acc: 0.9329\n",
      "         LR: 0.000010, Time: 1810.77s\n",
      "--------------------------------------------------\n",
      "Training completed!\n",
      "Best test accuracy: 0.9345\n",
      "Training completed successfully!\n",
      "Best model saved to: saved_models\\best_produce_classifier.pth\n",
      "Best test accuracy: 0.9345\n",
      "\n",
      "To load this model later, use:\n",
      "model, class_names, history = load_trained_model('saved_models\\best_produce_classifier.pth', device)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model and return training history\n",
    "    \"\"\"\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    print(f\"Training on {len(train_loader.dataset)} samples\")\n",
    "    print(f\"Testing on {len(test_loader.dataset)} samples\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    \n",
    "    best_test_acc = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print(f\"  Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_running_corrects = 0\n",
    "        \n",
    "  \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                test_running_loss += loss.item() * inputs.size(0)\n",
    "                test_running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "\n",
    "        test_loss = test_running_loss / len(test_loader.dataset)\n",
    "        test_acc = test_running_corrects.double() / len(test_loader.dataset)\n",
    "        \n",
    "\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc.item())\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc.item())\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Results - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "        print(f\"LR: {current_lr:.6f}, Time: {epoch_time:.2f}s\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(f\"Best test accuracy: {best_test_acc:.4f}\")\n",
    "    \n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "import os\n",
    "model_save_dir = \"saved_models\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "num_epochs = 15  \n",
    "\n",
    "\n",
    "\n",
    "trained_model, training_history = train_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs\n",
    ")\n",
    "\n",
    "\n",
    "model_save_path = os.path.join(model_save_dir, \"best_produce_classifier.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': trained_model.state_dict(),\n",
    "    'class_names': class_names,\n",
    "    'num_classes': num_classes,\n",
    "    'model_architecture': 'resnet18',\n",
    "    'best_test_accuracy': max(training_history['test_acc']),\n",
    "    'training_history': training_history\n",
    "}, model_save_path)\n",
    "\n",
    "\n",
    "def load_trained_model(model_path, device):\n",
    "    \"\"\"\n",
    "    Load a saved model for inference\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "\n",
    "    model = ProduceClassifier(num_classes=checkpoint['num_classes'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Architecture: {checkpoint['model_architecture']}\")\n",
    "    print(f\"Classes: {checkpoint['class_names']}\")\n",
    "    print(f\"Best accuracy: {checkpoint['best_test_accuracy']:.4f}\")\n",
    "    \n",
    "    return model, checkpoint['class_names'], checkpoint['training_history']\n",
    "\n",
    "print(f\"\\nTo load this model later, use:\")\n",
    "print(f\"model, class_names, history = load_trained_model('{model_save_path}', device)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
