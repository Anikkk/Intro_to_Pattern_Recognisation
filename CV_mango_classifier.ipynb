{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d939fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Mango Variation Classification\n",
      "Number of classes: 3\n",
      "Class names: ['Cubed,Hedgehog', 'Sliced,Peeled', 'Whole']\n",
      "Mango data directory: C:\\Users\\ashsh\\Downloads\\Mango\n",
      "\n",
      "=== MANGO VARIATIONS ===\n",
      "Cubed,Hedgehog: 1006 images\n",
      "Sliced,Peeled: 1509 images\n",
      "Whole: 1019 images\n",
      "\n",
      "=== SUMMARY ===\n",
      "Total mango images: 3534\n",
      "\n",
      "=== DATA QUALITY CHECK ===\n",
      "Cubed,Hedgehog: 1006 images - ✓ Good\n",
      "Sliced,Peeled: 1509 images - ✓ Good\n",
      "Whole: 1019 images - ✓ Good\n",
      "\n",
      "Ready to proceed with mango variation classification!\n",
      "This will be a 3-class classification problem.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Define mango variation classes based on your folder structure\n",
    "mango_variations = ['Cubed,Hedgehog', 'Sliced,Peeled', 'Whole']\n",
    "num_classes = len(mango_variations)\n",
    "\n",
    "print(f\"Mango Variation Classification\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {mango_variations}\")\n",
    "\n",
    "# Set data directory path (specifically for Mango folder)\n",
    "data_dir = r\"C:\\Users\\ashsh\\Downloads\"\n",
    "mango_folder = os.path.join(data_dir, \"Mango\")\n",
    "\n",
    "print(f\"Mango data directory: {mango_folder}\")\n",
    "\n",
    "# Explore mango folder structure and count images\n",
    "def explore_mango_variations(mango_path, variations):\n",
    "    total_images = 0\n",
    "    variation_counts = {}\n",
    "    \n",
    "    print(f\"\\n=== MANGO VARIATIONS ===\")\n",
    "    \n",
    "    if os.path.exists(mango_path):\n",
    "        for variation in variations:\n",
    "            variation_path = os.path.join(mango_path, variation)\n",
    "            if os.path.exists(variation_path):\n",
    "                images = [f for f in os.listdir(variation_path) \n",
    "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                count = len(images)\n",
    "                variation_counts[variation] = count\n",
    "                total_images += count\n",
    "                print(f\"{variation}: {count} images\")\n",
    "            else:\n",
    "                print(f\"Warning: {variation} folder not found at {variation_path}\")\n",
    "                variation_counts[variation] = 0\n",
    "    else:\n",
    "        print(f\"Error: Mango folder not found at {mango_path}\")\n",
    "    \n",
    "    print(f\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Total mango images: {total_images}\")\n",
    "    \n",
    "    return variation_counts, total_images\n",
    "\n",
    "# Explore the mango data\n",
    "variation_counts, total_images = explore_mango_variations(mango_folder, mango_variations)\n",
    "\n",
    "# Check if we have sufficient data for each class\n",
    "min_images_per_class = 100  # Minimum recommended images per class\n",
    "print(f\"\\n=== DATA QUALITY CHECK ===\")\n",
    "for variation, count in variation_counts.items():\n",
    "    status = \"✓ Good\" if count >= min_images_per_class else \"⚠ Low\"\n",
    "    print(f\"{variation}: {count} images - {status}\")\n",
    "\n",
    "if total_images > 0:\n",
    "    print(f\"\\nReady to proceed with mango variation classification!\")\n",
    "    print(f\"This will be a {num_classes}-class classification problem.\")\n",
    "else:\n",
    "    print(f\"\\nError: No mango images found. Please check the folder structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139f55ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Mango Variation Classification\n",
      "Number of classes: 3\n",
      "Class names: ['Cubed,Hedgehog', 'Sliced,Peeled', 'Whole']\n",
      "Creating mango variation datasets...\n",
      "Creating train dataset...\n",
      "  Cubed,Hedgehog: 804 images\n",
      "  Sliced,Peeled: 1207 images\n",
      "  Whole: 815 images\n",
      "Total train images: 2826\n",
      "Creating test dataset...\n",
      "  Cubed,Hedgehog: 202 images\n",
      "  Sliced,Peeled: 302 images\n",
      "  Whole: 204 images\n",
      "Total test images: 708\n",
      "DataLoaders created: batch_size=64\n",
      "Testing batch loading...\n",
      "✓ Batch test successful! Images: torch.Size([64, 3, 224, 224]), Labels: torch.Size([64])\n",
      "Creating ResNet model for mango variations...\n",
      "Backbone frozen - only training final layer\n",
      "Total parameters: 11,178,051\n",
      "Trainable parameters: 1,539\n",
      "Starting mango variation training...\n",
      "Starting training for 10 epochs...\n",
      "------------------------------------------------------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashsh\\AppData\\Local\\Temp\\ipykernel_36712\\36617082.py:162: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "C:\\Users\\ashsh\\AppData\\Local\\Temp\\ipykernel_36712\\36617082.py:190: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 15/45, Loss: 0.8452\n",
      "  Batch 30/45, Loss: 0.6463\n",
      "  Batch 45/45, Loss: 0.4557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashsh\\AppData\\Local\\Temp\\ipykernel_36712\\36617082.py:217: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8142, Train Acc: 0.6617\n",
      "Test Loss: 0.4978, Test Acc: 0.8729\n",
      "LR: 0.001000, Time: 667.7s\n",
      "Best Test Acc: 0.8729\n",
      "------------------------------------------------------------\n",
      "Epoch 2/10\n",
      "  Batch 15/45, Loss: 0.5970\n",
      "  Batch 30/45, Loss: 0.5204\n",
      "  Batch 45/45, Loss: 0.2350\n",
      "Train Loss: 0.4506, Train Acc: 0.8652\n",
      "Test Loss: 0.3877, Test Acc: 0.8884\n",
      "LR: 0.001000, Time: 875.1s\n",
      "Best Test Acc: 0.8884\n",
      "------------------------------------------------------------\n",
      "Epoch 3/10\n",
      "  Batch 15/45, Loss: 0.4005\n",
      "  Batch 30/45, Loss: 0.2733\n",
      "  Batch 45/45, Loss: 0.3820\n",
      "Train Loss: 0.3603, Train Acc: 0.8903\n",
      "Test Loss: 0.3390, Test Acc: 0.8955\n",
      "LR: 0.001000, Time: 776.9s\n",
      "Best Test Acc: 0.8955\n",
      "------------------------------------------------------------\n",
      "Epoch 4/10\n",
      "  Batch 15/45, Loss: 0.3965\n",
      "  Batch 30/45, Loss: 0.2657\n",
      "  Batch 45/45, Loss: 0.2238\n",
      "Train Loss: 0.3046, Train Acc: 0.9062\n",
      "Test Loss: 0.2721, Test Acc: 0.9181\n",
      "LR: 0.001000, Time: 623.5s\n",
      "Best Test Acc: 0.9181\n",
      "------------------------------------------------------------\n",
      "Epoch 5/10\n",
      "  Batch 15/45, Loss: 0.3702\n",
      "  Batch 30/45, Loss: 0.3131\n",
      "  Batch 45/45, Loss: 0.1837\n",
      "Train Loss: 0.2863, Train Acc: 0.9087\n",
      "Test Loss: 0.2694, Test Acc: 0.9124\n",
      "LR: 0.001000, Time: 646.9s\n",
      "Best Test Acc: 0.9181\n",
      "------------------------------------------------------------\n",
      "Epoch 6/10\n",
      "  Batch 15/45, Loss: 0.2626\n",
      "  Batch 30/45, Loss: 0.2233\n",
      "  Batch 45/45, Loss: 0.2423\n",
      "Train Loss: 0.2430, Train Acc: 0.9306\n",
      "Test Loss: 0.2072, Test Acc: 0.9322\n",
      "LR: 0.001000, Time: 637.0s\n",
      "Best Test Acc: 0.9322\n",
      "------------------------------------------------------------\n",
      "Epoch 7/10\n",
      "  Batch 15/45, Loss: 0.3142\n",
      "  Batch 30/45, Loss: 0.1804\n",
      "  Batch 45/45, Loss: 0.7710\n",
      "Train Loss: 0.2412, Train Acc: 0.9140\n",
      "Test Loss: 0.1936, Test Acc: 0.9421\n",
      "LR: 0.001000, Time: 652.8s\n",
      "Best Test Acc: 0.9421\n",
      "------------------------------------------------------------\n",
      "Epoch 8/10\n",
      "  Batch 15/45, Loss: 0.2975\n",
      "  Batch 30/45, Loss: 0.2198\n",
      "  Batch 45/45, Loss: 0.1387\n",
      "Train Loss: 0.2334, Train Acc: 0.9200\n",
      "Test Loss: 0.2426, Test Acc: 0.9153\n",
      "LR: 0.001000, Time: 625.4s\n",
      "Best Test Acc: 0.9421\n",
      "------------------------------------------------------------\n",
      "Epoch 9/10\n",
      "  Batch 15/45, Loss: 0.1873\n",
      "  Batch 30/45, Loss: 0.2579\n",
      "  Batch 45/45, Loss: 0.7680\n",
      "Train Loss: 0.2111, Train Acc: 0.9289\n",
      "Test Loss: 0.2246, Test Acc: 0.9266\n",
      "LR: 0.001000, Time: 653.7s\n",
      "Best Test Acc: 0.9421\n",
      "------------------------------------------------------------\n",
      "Epoch 10/10\n",
      "  Batch 15/45, Loss: 0.1781\n",
      "  Batch 30/45, Loss: 0.1933\n",
      "  Batch 45/45, Loss: 0.3278\n",
      "Train Loss: 0.2082, Train Acc: 0.9299\n",
      "Test Loss: 0.1776, Test Acc: 0.9421\n",
      "LR: 0.001000, Time: 653.5s\n",
      "Best Test Acc: 0.9421\n",
      "------------------------------------------------------------\n",
      "Training completed! Best test accuracy: 0.9421\n",
      "\n",
      "=== TRAINING COMPLETED ===\n",
      "Model saved to: saved_models/mango_variation_classifier.pth\n",
      "Best test accuracy: 0.9421\n",
      "Classes: ['Cubed,Hedgehog', 'Sliced,Peeled', 'Whole']\n",
      "\n",
      "To load this model later, use:\n",
      "model, class_names, history = load_mango_model('saved_models/mango_variation_classifier.pth', device)\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE MANGO VARIATION CLASSIFIER\n",
    "# Run this entire code block\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Set device and random seeds\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define mango variation classes\n",
    "mango_variations = ['Cubed,Hedgehog', 'Sliced,Peeled', 'Whole']\n",
    "num_classes = len(mango_variations)\n",
    "mango_folder = r\"C:\\Users\\ashsh\\Downloads\\Mango\"\n",
    "\n",
    "print(f\"Mango Variation Classification\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {mango_variations}\")\n",
    "\n",
    "# Custom Dataset class for mango variations\n",
    "class MangoVariationDataset(Dataset):\n",
    "    def __init__(self, mango_folder, variations, transform=None, train=True, train_split=0.8):\n",
    "        self.mango_folder = mango_folder\n",
    "        self.variations = variations\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {variation: idx for idx, variation in enumerate(variations)}\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"Creating {'train' if train else 'test'} dataset...\")\n",
    "        \n",
    "        for variation in variations:\n",
    "            variation_folder = os.path.join(mango_folder, variation)\n",
    "            if os.path.exists(variation_folder):\n",
    "                images_in_variation = []\n",
    "                for img_name in os.listdir(variation_folder):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        img_path = os.path.join(variation_folder, img_name)\n",
    "                        images_in_variation.append(img_path)\n",
    "                \n",
    "                train_imgs, test_imgs = train_test_split(images_in_variation, \n",
    "                                                       train_size=train_split, \n",
    "                                                       random_state=42)\n",
    "                \n",
    "                if train:\n",
    "                    selected_images = train_imgs\n",
    "                else:\n",
    "                    selected_images = test_imgs\n",
    "                \n",
    "                self.image_paths.extend(selected_images)\n",
    "                self.labels.extend([self.class_to_idx[variation]] * len(selected_images))\n",
    "                \n",
    "                print(f\"  {variation}: {len(selected_images)} images\")\n",
    "        \n",
    "        print(f\"Total {'train' if train else 'test'} images: {len(self.image_paths)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Data transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating mango variation datasets...\")\n",
    "train_dataset = MangoVariationDataset(mango_folder, mango_variations, \n",
    "                                     transform=train_transforms, train=True)\n",
    "test_dataset = MangoVariationDataset(mango_folder, mango_variations, \n",
    "                                    transform=test_transforms, train=False)\n",
    "\n",
    "# Create DataLoaders (no workers)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders created: batch_size={batch_size}\")\n",
    "\n",
    "# Test batch loading\n",
    "print(\"Testing batch loading...\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"✓ Batch test successful! Images: {sample_batch[0].shape}, Labels: {sample_batch[1].shape}\")\n",
    "\n",
    "# Model class\n",
    "class MangoVariationClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, pretrained=True, freeze_backbone=True):\n",
    "        super(MangoVariationClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.resnet.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "            print(\"Backbone frozen - only training final layer\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Create model\n",
    "print(\"Creating ResNet model for mango variations...\")\n",
    "model = MangoVariationClassifier(num_classes=num_classes, pretrained=True, freeze_backbone=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print parameter info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training function\n",
    "def train_mango_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [], 'learning_rates': []}\n",
    "    best_test_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    early_stop_patience = 5\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if (batch_idx + 1) % 15 == 0:\n",
    "                print(f\"  Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "        # Testing phase\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_running_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                test_running_loss += loss.item() * inputs.size(0)\n",
    "                test_running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        test_loss = test_running_loss / len(test_loader.dataset)\n",
    "        test_acc = test_running_corrects.double() / len(test_loader.dataset)\n",
    "        \n",
    "        scheduler.step(test_acc)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc.item())\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc.item())\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Save best model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Print results\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "        print(f\"LR: {current_lr:.6f}, Time: {epoch_time:.1f}s\")\n",
    "        print(f\"Best Test Acc: {best_test_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f\"Early stopping - no improvement for {early_stop_patience} epochs\")\n",
    "            break\n",
    "            \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Training completed! Best test accuracy: {best_test_acc:.4f}\")\n",
    "    return model, history\n",
    "\n",
    "# Start training\n",
    "print(\"Starting mango variation training...\")\n",
    "num_epochs = 10\n",
    "\n",
    "trained_model, training_history = train_mango_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs\n",
    ")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "model_save_path = \"saved_models/mango_variation_classifier.pth\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': trained_model.state_dict(),\n",
    "    'class_names': mango_variations,\n",
    "    'num_classes': num_classes,\n",
    "    'model_architecture': 'resnet18',\n",
    "    'best_test_accuracy': max(training_history['test_acc']),\n",
    "    'training_history': training_history\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"\\n=== TRAINING COMPLETED ===\")\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(f\"Best test accuracy: {max(training_history['test_acc']):.4f}\")\n",
    "print(f\"Classes: {mango_variations}\")\n",
    "\n",
    "# Function to load the model later\n",
    "def load_mango_model(model_path, device):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = MangoVariationClassifier(num_classes=checkpoint['num_classes'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model, checkpoint['class_names'], checkpoint['training_history']\n",
    "\n",
    "print(f\"\\nTo load this model later, use:\")\n",
    "print(f\"model, class_names, history = load_mango_model('{model_save_path}', device)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
