{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d187cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Broccoli Variation Classification\n",
      "Number of classes: 3\n",
      "Class names: ['Florets', 'In-Context(Cooking)', 'Whole Crown']\n",
      "Creating broccoli variation datasets...\n",
      "Creating train dataset...\n",
      "  Florets: 800 images\n",
      "  In-Context(Cooking): 800 images\n",
      "  Whole Crown: 800 images\n",
      "Total train images: 2400\n",
      "Creating test dataset...\n",
      "  Florets: 200 images\n",
      "  In-Context(Cooking): 200 images\n",
      "  Whole Crown: 200 images\n",
      "Total test images: 600\n",
      "DataLoaders created: batch_size=64\n",
      "Testing batch loading...\n",
      "✓ Batch test successful! Images: torch.Size([64, 3, 224, 224]), Labels: torch.Size([64])\n",
      "Creating ResNet model for broccoli variations...\n",
      "Backbone frozen - only training final layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashsh\\Downloads\\CV_Task\\cv_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ashsh\\Downloads\\CV_Task\\cv_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 11,178,051\n",
      "Trainable parameters: 1,539\n",
      "Starting broccoli variation training...\n",
      "Starting training for 10 epochs...\n",
      "------------------------------------------------------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashsh\\Downloads\\CV_Task\\cv_env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ashsh\\AppData\\Local\\Temp\\ipykernel_43652\\1494828417.py:160: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "C:\\Users\\ashsh\\AppData\\Local\\Temp\\ipykernel_43652\\1494828417.py:188: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 15/38, Loss: 0.9786\n",
      "  Batch 30/38, Loss: 0.8096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashsh\\AppData\\Local\\Temp\\ipykernel_43652\\1494828417.py:215: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9265, Train Acc: 0.5675\n",
      "Test Loss: 0.6468, Test Acc: 0.7833\n",
      "LR: 0.001000, Time: 360.5s\n",
      "Best Test Acc: 0.7833\n",
      "------------------------------------------------------------\n",
      "Epoch 2/10\n",
      "  Batch 15/38, Loss: 0.6195\n",
      "  Batch 30/38, Loss: 0.6614\n",
      "Train Loss: 0.6362, Train Acc: 0.7767\n",
      "Test Loss: 0.4878, Test Acc: 0.8267\n",
      "LR: 0.001000, Time: 351.7s\n",
      "Best Test Acc: 0.8267\n",
      "------------------------------------------------------------\n",
      "Epoch 3/10\n",
      "  Batch 15/38, Loss: 0.5324\n",
      "  Batch 30/38, Loss: 0.4931\n",
      "Train Loss: 0.5243, Train Acc: 0.8271\n",
      "Test Loss: 0.4042, Test Acc: 0.8700\n",
      "LR: 0.001000, Time: 343.9s\n",
      "Best Test Acc: 0.8700\n",
      "------------------------------------------------------------\n",
      "Epoch 4/10\n",
      "  Batch 15/38, Loss: 0.5121\n",
      "  Batch 30/38, Loss: 0.3942\n",
      "Train Loss: 0.4623, Train Acc: 0.8467\n",
      "Test Loss: 0.3792, Test Acc: 0.8683\n",
      "LR: 0.001000, Time: 339.0s\n",
      "Best Test Acc: 0.8700\n",
      "------------------------------------------------------------\n",
      "Epoch 5/10\n",
      "  Batch 15/38, Loss: 0.4318\n",
      "  Batch 30/38, Loss: 0.3878\n",
      "Train Loss: 0.4191, Train Acc: 0.8592\n",
      "Test Loss: 0.3392, Test Acc: 0.8817\n",
      "LR: 0.001000, Time: 353.2s\n",
      "Best Test Acc: 0.8817\n",
      "------------------------------------------------------------\n",
      "Epoch 6/10\n",
      "  Batch 15/38, Loss: 0.3703\n",
      "  Batch 30/38, Loss: 0.4803\n",
      "Train Loss: 0.3999, Train Acc: 0.8596\n",
      "Test Loss: 0.3191, Test Acc: 0.8950\n",
      "LR: 0.001000, Time: 358.5s\n",
      "Best Test Acc: 0.8950\n",
      "------------------------------------------------------------\n",
      "Epoch 7/10\n",
      "  Batch 15/38, Loss: 0.3681\n",
      "  Batch 30/38, Loss: 0.3743\n",
      "Train Loss: 0.3879, Train Acc: 0.8613\n",
      "Test Loss: 0.3059, Test Acc: 0.8883\n",
      "LR: 0.001000, Time: 348.2s\n",
      "Best Test Acc: 0.8950\n",
      "------------------------------------------------------------\n",
      "Epoch 8/10\n",
      "  Batch 15/38, Loss: 0.2998\n",
      "  Batch 30/38, Loss: 0.2984\n",
      "Train Loss: 0.3458, Train Acc: 0.8813\n",
      "Test Loss: 0.3367, Test Acc: 0.8783\n",
      "LR: 0.001000, Time: 327.1s\n",
      "Best Test Acc: 0.8950\n",
      "------------------------------------------------------------\n",
      "Epoch 9/10\n",
      "  Batch 15/38, Loss: 0.2769\n",
      "  Batch 30/38, Loss: 0.4006\n",
      "Train Loss: 0.3635, Train Acc: 0.8721\n",
      "Test Loss: 0.2730, Test Acc: 0.9067\n",
      "LR: 0.001000, Time: 332.0s\n",
      "Best Test Acc: 0.9067\n",
      "------------------------------------------------------------\n",
      "Epoch 10/10\n",
      "  Batch 15/38, Loss: 0.3187\n",
      "  Batch 30/38, Loss: 0.4217\n",
      "Train Loss: 0.3397, Train Acc: 0.8846\n",
      "Test Loss: 0.2752, Test Acc: 0.9017\n",
      "LR: 0.001000, Time: 331.4s\n",
      "Best Test Acc: 0.9067\n",
      "------------------------------------------------------------\n",
      "Training completed! Best test accuracy: 0.9067\n",
      "\n",
      "=== TRAINING COMPLETED ===\n",
      "Model saved to: saved_models/broccoli_variation_classifier.pth\n",
      "Best test accuracy: 0.9067\n",
      "Classes: ['Florets', 'In-Context(Cooking)', 'Whole Crown']\n",
      "\n",
      "To load this model later, use:\n",
      "model, class_names, history = load_broccoli_model('saved_models/broccoli_variation_classifier.pth', device)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Set device and random seeds\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define broccoli variation classes\n",
    "broccoli_variations = ['Florets', 'In-Context(Cooking)', 'Whole Crown']\n",
    "num_classes = len(broccoli_variations)\n",
    "broccoli_folder = r\"C:\\Users\\ashsh\\Downloads\\Broccoli\"\n",
    "\n",
    "print(f\"Broccoli Variation Classification\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {broccoli_variations}\")\n",
    "\n",
    "# Custom Dataset class for broccoli variations\n",
    "class BroccoliVariationDataset(Dataset):\n",
    "    def __init__(self, broccoli_folder, variations, transform=None, train=True, train_split=0.8):\n",
    "        self.broccoli_folder = broccoli_folder\n",
    "        self.variations = variations\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {variation: idx for idx, variation in enumerate(variations)}\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"Creating {'train' if train else 'test'} dataset...\")\n",
    "        \n",
    "        for variation in variations:\n",
    "            variation_folder = os.path.join(broccoli_folder, variation)\n",
    "            if os.path.exists(variation_folder):\n",
    "                images_in_variation = []\n",
    "                for img_name in os.listdir(variation_folder):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        img_path = os.path.join(variation_folder, img_name)\n",
    "                        images_in_variation.append(img_path)\n",
    "                \n",
    "                train_imgs, test_imgs = train_test_split(images_in_variation, \n",
    "                                                       train_size=train_split, \n",
    "                                                       random_state=42)\n",
    "                \n",
    "                if train:\n",
    "                    selected_images = train_imgs\n",
    "                else:\n",
    "                    selected_images = test_imgs\n",
    "                \n",
    "                self.image_paths.extend(selected_images)\n",
    "                self.labels.extend([self.class_to_idx[variation]] * len(selected_images))\n",
    "                \n",
    "                print(f\"  {variation}: {len(selected_images)} images\")\n",
    "        \n",
    "        print(f\"Total {'train' if train else 'test'} images: {len(self.image_paths)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Data transforms optimized for broccoli variations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),  # Good rotation for broccoli\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),  # Preserve green tones\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.3),  # Slight perspective changes\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating broccoli variation datasets...\")\n",
    "train_dataset = BroccoliVariationDataset(broccoli_folder, broccoli_variations, \n",
    "                                        transform=train_transforms, train=True)\n",
    "test_dataset = BroccoliVariationDataset(broccoli_folder, broccoli_variations, \n",
    "                                       transform=test_transforms, train=False)\n",
    "\n",
    "# Create DataLoaders (no workers)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders created: batch_size={batch_size}\")\n",
    "\n",
    "# Test batch loading\n",
    "print(\"Testing batch loading...\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"✓ Batch test successful! Images: {sample_batch[0].shape}, Labels: {sample_batch[1].shape}\")\n",
    "\n",
    "# Model class\n",
    "class BroccoliVariationClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, pretrained=True, freeze_backbone=True):\n",
    "        super(BroccoliVariationClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.resnet.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "            print(\"Backbone frozen - only training final layer\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Create model\n",
    "print(\"Creating ResNet model for broccoli variations...\")\n",
    "model = BroccoliVariationClassifier(num_classes=num_classes, pretrained=True, freeze_backbone=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print parameter info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training function\n",
    "def train_broccoli_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [], 'learning_rates': []}\n",
    "    best_test_acc = 0.0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    early_stop_patience = 5\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if (batch_idx + 1) % 15 == 0:\n",
    "                print(f\"  Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "        # Testing phase\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_running_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                test_running_loss += loss.item() * inputs.size(0)\n",
    "                test_running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        test_loss = test_running_loss / len(test_loader.dataset)\n",
    "        test_acc = test_running_corrects.double() / len(test_loader.dataset)\n",
    "        \n",
    "        scheduler.step(test_acc)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc.item())\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc.item())\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Save best model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Print results\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "        print(f\"LR: {current_lr:.6f}, Time: {epoch_time:.1f}s\")\n",
    "        print(f\"Best Test Acc: {best_test_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f\"Early stopping - no improvement for {early_stop_patience} epochs\")\n",
    "            break\n",
    "            \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Training completed! Best test accuracy: {best_test_acc:.4f}\")\n",
    "    return model, history\n",
    "\n",
    "# Start training\n",
    "print(\"Starting broccoli variation training...\")\n",
    "num_epochs = 10\n",
    "\n",
    "trained_model, training_history = train_broccoli_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs\n",
    ")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "model_save_path = \"saved_models/broccoli_variation_classifier.pth\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': trained_model.state_dict(),\n",
    "    'class_names': broccoli_variations,\n",
    "    'num_classes': num_classes,\n",
    "    'model_architecture': 'resnet18',\n",
    "    'best_test_accuracy': max(training_history['test_acc']),\n",
    "    'training_history': training_history\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"\\n=== TRAINING COMPLETED ===\")\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(f\"Best test accuracy: {max(training_history['test_acc']):.4f}\")\n",
    "print(f\"Classes: {broccoli_variations}\")\n",
    "\n",
    "# Function to load the model later\n",
    "def load_broccoli_model(model_path, device):\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = BroccoliVariationClassifier(num_classes=checkpoint['num_classes'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model, checkpoint['class_names'], checkpoint['training_history']\n",
    "\n",
    "print(f\"\\nTo load this model later, use:\")\n",
    "print(f\"model, class_names, history = load_broccoli_model('{model_save_path}', device)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
